{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load rgb original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1440\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the image\n",
    "image_path = \"../../datasets/ring_try_on_input_data/images/original_0.png\"  # Replace with the path to your hand image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to RGB (Mediapipe uses RGB images)\n",
    "imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "imgWidth, imgHeight = len(imageRGB[0]), len(imageRGB)\n",
    "print(imgWidth, imgHeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MediaPipe to detect hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark 0: x=0.715581476688385, y=0.4338538646697998, z=3.717768777278252e-07\n",
      "Landmark 1: x=0.7039138078689575, y=0.5395265221595764, z=-0.013928795233368874\n",
      "Landmark 2: x=0.6543437838554382, y=0.6085299253463745, z=-0.024222364649176598\n",
      "Landmark 3: x=0.5916611552238464, y=0.635909914970398, z=-0.03132377564907074\n",
      "Landmark 4: x=0.5426812767982483, y=0.663235604763031, z=-0.03824285790324211\n",
      "Landmark 5: x=0.5637412667274475, y=0.558074951171875, z=-0.03281363099813461\n",
      "Landmark 6: x=0.4728052616119385, y=0.5733675956726074, z=-0.04696201905608177\n",
      "Landmark 7: x=0.42245492339134216, y=0.5797991752624512, z=-0.05384199693799019\n",
      "Landmark 8: x=0.3819367289543152, y=0.583411455154419, z=-0.057277824729681015\n",
      "Landmark 9: x=0.5528971552848816, y=0.49372825026512146, z=-0.034468427300453186\n",
      "Landmark 10: x=0.4579400420188904, y=0.5157116651535034, z=-0.04545045644044876\n",
      "Landmark 11: x=0.3998931646347046, y=0.5243610143661499, z=-0.05225352197885513\n",
      "Landmark 12: x=0.3568154573440552, y=0.5274691581726074, z=-0.05688917264342308\n",
      "Landmark 13: x=0.5581879615783691, y=0.43377527594566345, z=-0.036249201744794846\n",
      "Landmark 14: x=0.471347451210022, y=0.44997096061706543, z=-0.0486130490899086\n",
      "Landmark 15: x=0.4162343740463257, y=0.4543582797050476, z=-0.05763626843690872\n",
      "Landmark 16: x=0.3752741813659668, y=0.4575252830982208, z=-0.06322836130857468\n",
      "Landmark 17: x=0.5718212723731995, y=0.3783160448074341, z=-0.03802913799881935\n",
      "Landmark 18: x=0.5033935904502869, y=0.39269453287124634, z=-0.049727339297533035\n",
      "Landmark 19: x=0.46129724383354187, y=0.40304654836654663, z=-0.05484224110841751\n",
      "Landmark 20: x=0.4251928925514221, y=0.41253185272216797, z=-0.056758612394332886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738305688.896836    2214 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 4\n",
      "I0000 00:00:1738305688.934984    2398 gl_context.cc:369] GL version: 3.0 (OpenGL ES 3.0 Mesa 21.2.6), renderer: D3D12 (NVIDIA GeForce RTX 3060 Laptop GPU)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1738305688.974721    2367 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738305688.991664    2369 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1738305689.011675    2378 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "# Initialize the Hand Tracking model\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5) as hands:\n",
    "    # Process the image\n",
    "    results = hands.process(imageRGB)\n",
    "\n",
    "    # Check if any hands are detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw the landmarks on the original image\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Print landmark coordinates\n",
    "            for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                print(f\"Landmark {idx}: x={landmark.x}, y={landmark.y}, z={landmark.z}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No hands detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.15581477e-01  4.33853865e-01  3.71776878e-07]\n",
      " [ 7.03913808e-01  5.39526522e-01 -1.39287952e-02]\n",
      " [ 6.54343784e-01  6.08529925e-01 -2.42223646e-02]\n",
      " [ 5.91661155e-01  6.35909915e-01 -3.13237756e-02]\n",
      " [ 5.42681277e-01  6.63235605e-01 -3.82428579e-02]\n",
      " [ 5.63741267e-01  5.58074951e-01 -3.28136310e-02]\n",
      " [ 4.72805262e-01  5.73367596e-01 -4.69620191e-02]\n",
      " [ 4.22454923e-01  5.79799175e-01 -5.38419969e-02]\n",
      " [ 3.81936729e-01  5.83411455e-01 -5.72778247e-02]\n",
      " [ 5.52897155e-01  4.93728250e-01 -3.44684273e-02]\n",
      " [ 4.57940042e-01  5.15711665e-01 -4.54504564e-02]\n",
      " [ 3.99893165e-01  5.24361014e-01 -5.22535220e-02]\n",
      " [ 3.56815457e-01  5.27469158e-01 -5.68891726e-02]\n",
      " [ 5.58187962e-01  4.33775276e-01 -3.62492017e-02]\n",
      " [ 4.71347451e-01  4.49970961e-01 -4.86130491e-02]\n",
      " [ 4.16234374e-01  4.54358280e-01 -5.76362684e-02]\n",
      " [ 3.75274181e-01  4.57525283e-01 -6.32283613e-02]\n",
      " [ 5.71821272e-01  3.78316045e-01 -3.80291380e-02]\n",
      " [ 5.03393590e-01  3.92694533e-01 -4.97273393e-02]\n",
      " [ 4.61297244e-01  4.03046548e-01 -5.48422411e-02]\n",
      " [ 4.25192893e-01  4.12531853e-01 -5.67586124e-02]]\n"
     ]
    }
   ],
   "source": [
    "points = results.multi_hand_landmarks\n",
    "\n",
    "handLandmarks = list()\n",
    "\n",
    "i = 1\n",
    "for hand_landmarks in results.multi_hand_landmarks:\n",
    "    # Draw the landmarks on the original image\n",
    "    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Print landmark coordinates\n",
    "    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "        handLandmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "handLandmarks = np.array(handLandmarks)\n",
    "print(handLandmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from LiDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthLogs = \"../../datasets/ring_try_on_input_data/images/depth_logs_0.txt\"  # Replace with the path to your hand image\n",
    "depthData = np.loadtxt(depthLogs, delimiter=\",\")\n",
    "print(depthData)\n",
    "print(len(depthData))\n",
    "print(len(depthData[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizedDepthData = cv2.resize(depthData, (1920, 1440), interpolation=cv2.INTER_CUBIC)\n",
    "resizedDepthData = resizedDepthData * 1000 # from mm to meters ?\n",
    "print(resizedDepthData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/ring_try_on_input_data/images/depth_calibration_logs_1.txt\", \"r\") as f:\n",
    "    lines = f.readlines()[1:4]\n",
    "\n",
    "intrinsics = np.array([list(map(float, line.split(','))) for line in lines])\n",
    "fx, fy, cx, cy = intrinsics[0][0], intrinsics[1][1], intrinsics[0][2], intrinsics[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get point cloud of hand landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks3D = list()\n",
    "h, w = resizedDepthData.shape\n",
    "for landmark in handLandmarks:\n",
    "    xL, yL = int(landmark[0] * w), int(landmark[1] * h)\n",
    "    depthXY = resizedDepthData[yL, xL]\n",
    "    x3d = (xL - cx) * depthXY / fx\n",
    "    y3d = (yL - cy) * depthXY / fy\n",
    "    z3d = depthXY\n",
    "    landmarks3D.append([x3d, y3d, z3d])\n",
    "\n",
    "landmarks3D = np.array(landmarks3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find ring basis vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ring finger\n",
    "landmark5, landmark6, landmark9 = landmarks3D[5], landmarks3D[6], landmarks3D[9]\n",
    "\n",
    "ringPosition = (landmark5 + landmark6) / 2\n",
    "\n",
    "xAxisDirection = (landmark6 - landmark5)\n",
    "xAxis = xAxisDirection / np.linalg.norm(xAxisDirection)\n",
    "\n",
    "yAxisDirection = (landmark9 - landmark5)\n",
    "yAxis = yAxisDirection / np.linalg.norm(yAxisDirection)\n",
    "\n",
    "zAxisDirection = np.cross(xAxisDirection, yAxisDirection)\n",
    "zAxis = zAxisDirection / np.linalg.norm(zAxisDirection)\n",
    "\n",
    "# Recompute yAxis to be perpendicular to xAxis\n",
    "yAxisNewDirection = np.cross(zAxis, xAxis)\n",
    "yAxis = yAxisNewDirection / np.linalg.norm(yAxisNewDirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xAxis)\n",
    "print(yAxis)\n",
    "print(zAxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forming transformation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xForTMatrix = yAxis\n",
    "yForTMatrix = xAxis\n",
    "zForTMatrix = -1 * zAxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xForTMatrix)\n",
    "print(yForTMatrix)\n",
    "print(zForTMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformMatrix = np.eye(4)\n",
    "transformMatrix[:3, 0] = xForTMatrix\n",
    "transformMatrix[:3, 1] = yForTMatrix\n",
    "transformMatrix[:3, 2] = zForTMatrix\n",
    "transformMatrix[:3, 3] = ringPosition\n",
    "\n",
    "print(transformMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ringPosition)\n",
    "print()\n",
    "print(transformMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ringPosition_homogeneous = np.append(ringPosition, 1)\n",
    "cameraPose = np.matmul(transformMatrix, ringPosition_homogeneous)\n",
    "print(cameraPose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Create new variables for scaled vectors\n",
    "xAxis_scaled = xForTMatrix * 50\n",
    "yAxis_scaled = yForTMatrix * 50\n",
    "zAxis_scaled = zForTMatrix * 50\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot the vectors using the quiver function with scaled vectors\n",
    "fig.add_trace(go.Cone(\n",
    "    x=[ringPosition[0]], y=[ringPosition[1]], z=[ringPosition[2]],\n",
    "    u=[xAxis_scaled[0]], v=[xAxis_scaled[1]], w=[xAxis_scaled[2]],\n",
    "    colorscale='reds', sizemode=\"scaled\", showscale=False, anchor=\"tail\"\n",
    "))\n",
    "fig.add_trace(go.Cone(\n",
    "    x=[ringPosition[0]], y=[ringPosition[1]], z=[ringPosition[2]],\n",
    "    u=[yAxis_scaled[0]], v=[yAxis_scaled[1]], w=[yAxis_scaled[2]],\n",
    "    colorscale='greens', sizemode=\"scaled\", showscale=False, anchor=\"tail\"\n",
    "))\n",
    "fig.add_trace(go.Cone(\n",
    "    x=[ringPosition[0]], y=[ringPosition[1]], z=[ringPosition[2]],\n",
    "    u=[zAxis_scaled[0]], v=[zAxis_scaled[1]], w=[zAxis_scaled[2]],\n",
    "    colorscale='blues', sizemode=\"scaled\", showscale=False, anchor=\"tail\"\n",
    "))\n",
    "\n",
    "# Plot the 3D landmarks\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=landmarks3D[:, 0], y=landmarks3D[:, 1], z=landmarks3D[:, 2],\n",
    "    mode='markers', marker=dict(size=5, color='black')\n",
    "))\n",
    "\n",
    "# Define camera view\n",
    "\n",
    "# Set axis labels\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X-axis',\n",
    "        yaxis_title='Y-axis',\n",
    "        zaxis_title='Z-axis'\n",
    "    ),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,  # Increase figure width\n",
    "    height=800,  # Increase figure height\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Blender Rendering\n",
    "\n",
    "\"C:\\Program Files\\Blender Foundation\\Blender 4.3\\blender.exe\" \"C:\\Users\\Владелец\\Downloads\\kilce_001.blend\" --background --python \"C:\\Users\\Владелец\\Downloads\\blender_renderer.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "from pathlib import Path\n",
    "from mathutils import Matrix\n",
    "import numpy as np\n",
    "\n",
    "class BlenderRenderSetup:\n",
    "    def __init__(self, p_root: Path, dn_ext=\"OPEN_EXR\"):\n",
    "        assert dn_ext in [\"OPEN_EXR\", \"PNG\"]\n",
    "\n",
    "        self.camera_name: str = None\n",
    "        self.camera = None\n",
    "        self.tree = None\n",
    "\n",
    "        self.p_root = p_root\n",
    "        self.p_out_render = None\n",
    "        self.dn_ext = dn_ext.upper()\n",
    "\n",
    "    def _set_camera(\n",
    "            self,\n",
    "            camera_name: str,\n",
    "    ) -> None:\n",
    "        self.camera = bpy.data.objects.get(camera_name)\n",
    "        assert self.camera is not None\n",
    "        self.camera_name = camera_name\n",
    "\n",
    "    def _set_render_path(\n",
    "            self\n",
    "    ) -> None:\n",
    "        assert self.camera_name\n",
    "        self.p_out_render = Path(self.p_root) / self.camera_name\n",
    "        self.p_out_render.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def _set_context(\n",
    "            self,\n",
    "            px: int = 1024,\n",
    "            py: int = 1024,\n",
    "    ) -> None:\n",
    "        assert self.camera is not None\n",
    "        bpy.context.scene.camera = self.camera\n",
    "        bpy.context.scene.render.resolution_x = px\n",
    "        bpy.context.scene.render.resolution_y = py\n",
    "        bpy.context.scene.use_nodes = True\n",
    "\n",
    "        bpy.context.view_layer.use_pass_z = True\n",
    "        bpy.context.view_layer.use_pass_normal = True\n",
    "        bpy.context.view_layer.use_pass_object_index = True\n",
    "        bpy.context.scene.render.film_transparent = True\n",
    "\n",
    "    def _get_output_node(\n",
    "            self,\n",
    "            tree,\n",
    "            label,\n",
    "            file_format: str,\n",
    "            use_alpha: str = False\n",
    "    ):\n",
    "        base_path = self.p_out_render / f\"_{label}\"\n",
    "        base_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        node = tree.nodes.new(type=\"CompositorNodeOutputFile\")\n",
    "        node.base_path = str(base_path)\n",
    "        node.format.file_format = file_format\n",
    "\n",
    "        if use_alpha:\n",
    "            node.format.color_mode = 'RGBA'\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _set_nodes_tree(\n",
    "            self\n",
    "    ) -> None:\n",
    "        self.tree = bpy.context.scene.node_tree\n",
    "        self.tree.nodes.clear()\n",
    "\n",
    "        self.render_layers = self.tree.nodes.new(type=\"CompositorNodeRLayers\")\n",
    "        self.composite = self.tree.nodes.new(type=\"CompositorNodeComposite\")\n",
    "\n",
    "        self.file_output_color = self._get_output_node(self.tree, \"color\", \"PNG\", use_alpha=True)\n",
    "        self.file_output_depth = self._get_output_node(self.tree, \"depth\", self.dn_ext)\n",
    "        self.file_output_normal = self._get_output_node(self.tree, \"normal\", self.dn_ext)\n",
    "    def _link_nodes(self):\n",
    "        assert self.tree is not None\n",
    "\n",
    "        print(self.render_layers.outputs)\n",
    "        self.tree.links.new(self.render_layers.outputs[\"Image\"], self.file_output_color.inputs[0])\n",
    "        self.tree.links.new(self.render_layers.outputs[\"Depth\"], self.file_output_depth.inputs[0])\n",
    "        self.tree.links.new(self.render_layers.outputs[\"Normal\"], self.file_output_normal.inputs[0])\n",
    "        # self.tree.links.new(self.render_layers.outputs[\"IndexOB\"], self.file_output_mask.inputs[0])\n",
    "        self.tree.links.new(self.render_layers.outputs[\"Image\"], self.composite.inputs[0])\n",
    "\n",
    "    def _transform_matrix_to_euler(self, transform_matrix):\n",
    "        rotation_matrix = transform_matrix[:3, :3]\n",
    "        location = transform_matrix[:3, 3]\n",
    "        euler_angles = Matrix(rotation_matrix).to_euler()\n",
    "        return euler_angles, location\n",
    "\n",
    "    def _setup(\n",
    "            self,\n",
    "            camera_name: str,\n",
    "            px: int = 1920,\n",
    "            py: int = 1440,\n",
    "    ) -> None:\n",
    "        self._set_camera(camera_name)\n",
    "        self._set_render_path()\n",
    "        self._set_context(px=px, py=py)\n",
    "        self._set_nodes_tree()\n",
    "        self._link_nodes()\n",
    "\n",
    "        # transform_matrix = np.array([[-1.83043312e-01, -9.01450335e-01, -3.92278524e-01,  2.99722454e+01],\n",
    "        #                              [-9.61303787e-01,  8.05525760e-02,  2.63450778e-01,  3.63439362e+01],\n",
    "        #                              [-2.05888746e-01,  4.25321733e-01, -8.81312230e-01,  3.40888294e+02],\n",
    "        #                              [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]\n",
    "        #                              ])\n",
    "\n",
    "        # m2 = np.array([[1, 0, 0,  -0.06836785606168191],\n",
    "        #                [0, 1, 0, -0.2043487541167911],\n",
    "        #                [0, 0, 1,  0],\n",
    "        #                [0, 0, 0,   1]])\n",
    "        \n",
    "        #euler_camera, camera_location = self._transform_matrix_to_euler(m2)\n",
    "\n",
    "        euler_angles, location = self._transform_matrix_to_euler(transformMatrix)\n",
    "\n",
    "        bpy.data.objects[\"ring\"].location = (location[1], location[0], location[2])\n",
    "        bpy.data.objects[\"ring\"].rotation_euler = euler_angles\n",
    "        # bpy.data.objects[\"bottom\"].location = camera_location\n",
    "        # bpy.data.objects[\"bottom\"].rotation_euler = euler_camera\n",
    "\n",
    "    def _render(\n",
    "            self\n",
    "    ) -> None:\n",
    "        bpy.ops.render.render(write_still=True)\n",
    "        print(f\"Rendered color, depth, and normal maps saved to {self.p_out_render}\")\n",
    "\n",
    "    def render(\n",
    "            self,\n",
    "            camera_name: str,\n",
    "            px: int = 1920,\n",
    "            py: int = 1440,\n",
    "    ) -> None:\n",
    "        self._setup(\n",
    "            camera_name=camera_name,\n",
    "            px=px, py=py\n",
    "        )\n",
    "\n",
    "        assert self.camera is not None\n",
    "        assert self.tree is not None\n",
    "\n",
    "        self._render()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p_root = Path(r\"./\")\n",
    "\n",
    "    renderer = BlenderRenderSetup(p_root)\n",
    "    for view in ['bottom', 'front']:\n",
    "        renderer.render(view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put RGBA image on top of original RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def overlay_images(rgb_image_path, rgba_image_path, output_image_path):\n",
    "    rgb_image = Image.open(rgb_image_path).convert(\"RGB\")\n",
    "    rgba_image = Image.open(rgba_image_path).convert(\"RGBA\")\n",
    "\n",
    "    rgba_image = rgba_image.resize(rgb_image.size)\n",
    "\n",
    "    background = rgb_image.convert(\"RGBA\")\n",
    "    overlay = Image.alpha_composite(background, rgba_image)\n",
    "\n",
    "    overlay.save(output_image_path)\n",
    "\n",
    "def rgb_to_rgba(rgb_image_path, output_image_path):\n",
    "    rgb_image = Image.open(rgb_image_path).convert(\"RGB\")\n",
    "    rgba_image = rgb_image.convert(\"RGBA\")\n",
    "    rgba_image.save(output_image_path)\n",
    "\n",
    "overlay_images('original_1.png', 'ringRGBA.png', 'output_image1.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ringTryOnEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
